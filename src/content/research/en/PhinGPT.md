---
title: "PhinGPT: A Homemade Language Model for the Financial Sector"
description: "Large language models are revolutionizing various fields of knowledge. This work aims to train a specialized model for the financial sector by optimizing computational costs with optimal training. We present Qlora, a fine-tuning method that reduces computational costs. We evaluate the performance of the model trained with this method and compare it with the original model in the tasks of named entity recognition (NER) and word analysis."
researchers: ["Tuli pe√±a", "Robert Gomez", "Francisco Jose"]
status: "completed"
startDate: 2024-01-15
tags: ["Finance", "AI", "PhinGPT", "LLMS"]
lang: "en"
translationKey: "PhinGPT: A Homemade Language Model for the Financial Sector"
---

# Explainable AI for Medical Diagnosis

## Overview

This research project focuses on developing transparent and interpretable deep learning models for medical image analysis. While current deep learning approaches achieve high accuracy in medical diagnosis tasks, they often function as "black boxes," making it difficult for healthcare professionals to understand and trust their predictions. Our goal is to create models that not only provide accurate diagnoses but also explain their reasoning in clinically meaningful ways.

## Research Objectives

1. Develop novel attention-based visualization techniques to highlight relevant regions in medical images that influence the model's decision
2. Create hybrid architectures that combine the strengths of deep learning with transparent, rule-based systems
3. Design interactive interfaces that allow clinicians to explore and understand model predictions
4. Validate the clinical utility of explainable models through collaboration with healthcare professionals

## Current Progress

We have developed a prototype system for chest X-ray analysis that provides visual explanations alongside its predictions. Preliminary evaluations with radiologists show that explanations significantly improve their trust in the system and help identify potential model errors. Our approach combines gradient-based attribution methods with anatomically-aware attention mechanisms.

## Future Work

We are expanding our research to include additional imaging modalities such as MRI and CT scans. We are also exploring how language models can generate natural language explanations that describe the reasoning behind diagnoses in terminology familiar to healthcare practitioners.
